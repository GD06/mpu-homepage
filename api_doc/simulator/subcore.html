<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.8.3" />
<title>simulator.subcore API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js" integrity="sha256-eOgo0OtLL4cdq7RdwRUiGKLX9XsIJ7nGhWEKbohmVAQ=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>simulator.subcore</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import simpy 
from copy import deepcopy 

from simulator.subcore_table import WarpInfoTable, WarpPipelineTable, StackTable 
from simulator.subcore_table import WarpPipelineTableEntry, DepTable, \
    RegTrackTable
from simulator.instr_cache import InstrLoadReq  
from simulator.register_file import RegisterFile 
from simulator.operand_collector import OperandCollector
from simulator.alu import ArithmeticLogicUnit
from simulator.sfu import SpecialFunctionUnit
from simulator.load_store_unit import LoadStoreUnit
from simulator.synchronization_unit import SynchronizationUnit
from simulator.control_flow_unit import ControlFlowUnit
from simulator.instr_instance import InstrEntry
from simulator.register_file_utility import RegFileOperandIOInterface, \
    OperandWriteReq
from simulator.instr_offload_engine import InstrOffloadEngine
from simulator.reg_move_engine import RegMoveEngine, RegMoveReq


class Subcore:

    def __init__(self, subcore_id, env, config, log, core):
        self.subcore_id = subcore_id 
        self.env = env 
        self.config = config 
        self.log = log
        self.core = core

        self.clock_unit = deepcopy(core.clock_unit) 
        self._loc_str = &#34;Processor ID: {proc_id}, Core ID: {core_id}, &#34; \
            &#34;Subcore ID: {subcore_id}&#34;.format(
                proc_id=self.core.processor.proc_id,
                core_id=self.core.core_id,
                subcore_id=self.subcore_id, 
            )

        self.start_exec_cmd = simpy.Store(env, capacity=1)
        self.finish_exec_resp = simpy.Store(env, capacity=1) 

        self.num_active_warps = 0
        self.warp_info_table = WarpInfoTable(config=self.config, log=self.log) 
        self.warp_pipeline_table = \
            WarpPipelineTable(config=self.config, log=self.log)
        self.stack_table = StackTable(config=self.config, log=self.log)
        self.dep_table = DepTable(config=self.config, log=self.log)

        self.reg_file = RegisterFile(
            env=env, 
            log=log, 
            config=self.config,
            clock_unit=self.clock_unit,  
            reg_file_type=&#34;far-bank&#34;
        )

        self.reg_track_table = RegTrackTable(
            config=self.config,
            log=self.log,
            reg_file=self.reg_file
        )

        self.rf_io_interface = RegFileOperandIOInterface(
            env=self.env,
            log=self.log,
            config=self.config,
            clock_unit=self.clock_unit,
            reg_file=self.reg_file,
            interface_type=&#34;far-bank&#34;,
        )

        self.reg_move_engine = RegMoveEngine(
            env=self.env,
            log=self.log,
            config=self.config,
            clock_unit=self.clock_unit,
            backend=self,
            regfile_io_interface=self.rf_io_interface,
            bus_arbiter=self.core.subcore_pg_bus_arbiter,
            engine_type=&#34;fb_reg_move&#34;
        )

        self.instr_offload_engine = InstrOffloadEngine(
            env=self.env,
            config=self.config,
            log=self.log,
            reg_move_engine=self.reg_move_engine,
            subcore=self
        )

        # TODO make this port assignment more accurate
        # currently round-robin
        self.local_regfile_write_port_id_commit = 0
        self.base_regfile_write_port_id_commit = \
            self.config[&#34;base_regfile_write_port_id_fb_commit&#34;]

        self.decode_buffer = []
        self.num_free_decode_buffer_slots = []
        for i in range(self.config[&#34;max_num_warp_per_subcore&#34;]):
            self.decode_buffer.append(simpy.Store(env))
            self.num_free_decode_buffer_slots.append(
                self.config[&#34;decode_buffer_size&#34;])

        self.execute_buffer = simpy.Store(
            env, capacity=(self.config[&#34;subcore_execute_buffer_size&#34;])
        )

        self.writeback_buffer = simpy.Store(
            env, capacity=self.config[&#34;subcore_writeback_buffer_size&#34;]
        )

        self.sync_buffer = simpy.Store(
            env, capacity=self.config[&#34;max_num_warp_per_subcore&#34;]
        )

        self.bus_receive_buffer = simpy.Store(
            env, capacity=self.config[&#34;subcore_bus_receive_buffer_size&#34;]
        )

        self.reg_base_ptr = 0

        # Execution Stage
        # arithemtic logic unit
        self.fb_alu = ArithmeticLogicUnit(
            env=self.env,
            log=self.log,
            config=self.config,
            clock_unit=self.clock_unit,
            backend=self,
            alu_type=&#34;far-bank&#34;
        )
        self.opc_fb_alu = OperandCollector(
            env=self.env,
            log=self.log,
            config=self.config,
            clock_unit=self.clock_unit,
            backend=self,
            regfile_io_interface=self.rf_io_interface,
            execution_unit=self.fb_alu,
            opc_type=&#34;fb_alu&#34;
        )
        
        # special function unit
        self.sfu = SpecialFunctionUnit(
            env=self.env,
            log=self.log,
            config=self.config,
            clock_unit=self.clock_unit,
            subcore=self
        )
        self.opc_sfu = OperandCollector(
            env=self.env,
            log=self.log,
            config=self.config,
            clock_unit=self.clock_unit,
            backend=self,
            regfile_io_interface=self.rf_io_interface,
            execution_unit=self.sfu,
            opc_type=&#34;sfu&#34;
        )

        # load-store unit
        self.lsu = LoadStoreUnit(
            env=self.env,
            log=self.log,
            config=self.config,
            clock_unit=self.clock_unit,
            subcore=self
        )
        self.opc_lsu = OperandCollector(
            env=self.env,
            log=self.log,
            config=self.config,
            clock_unit=self.clock_unit,
            backend=self,
            regfile_io_interface=self.rf_io_interface,
            execution_unit=self.lsu,
            opc_type=&#34;lsu&#34;
        )

        # control-flow unit
        self.cfu = ControlFlowUnit(
            env=self.env,
            log=self.log,
            config=self.config,
            clock_unit=self.clock_unit,
            subcore=self
        )
        self.opc_cfu = OperandCollector(
            env=self.env,
            log=self.log,
            config=self.config,
            clock_unit=self.clock_unit,
            backend=self,
            regfile_io_interface=self.rf_io_interface,
            execution_unit=self.cfu,
            opc_type=&#34;cfu&#34;
        )

        # synchronization unit
        self.syncu = SynchronizationUnit(
            env=self.env,
            log=self.log,
            config=self.config,
            clock_unit=self.clock_unit,
            subcore=self
        )
        self.opc_syncu = OperandCollector(
            env=self.env,
            log=self.log,
            config=self.config,
            clock_unit=self.clock_unit,
            backend=self,
            regfile_io_interface=self.rf_io_interface,
            execution_unit=self.syncu,
            opc_type=&#34;syncu&#34;
        )

        # Spawn a process for the fetch and decode subcore stages
        self.env.process(self._fetch_and_decode())

        # Spawn processes for the issue subcore stage
        for i in range(self.config[&#34;max_num_warp_per_subcore&#34;]):
            self.env.process(self._issue(entry_id=i))

        # Spawn a process for the execute subcore stage 
        self.env.process(self._execute())

        # Spawn a process for the commit subcore stage 
        self.env.process(self._commit())

        # Spawn a process to receive data from the bus
        self.env.process(self._receive_bus_data())
        return 

    def reset_status(self):
        &#34;&#34;&#34;Reset hardware status of subcores.This function is usually used 
        to reset subcore status between different calls of executing thread 
        blocks. 
        &#34;&#34;&#34;
        self.num_active_warps = 0
        self.reg_base_ptr = 0

        # Reset the tables in the subcore  
        self.warp_info_table.reset()
        self.warp_pipeline_table.reset() 
        self.stack_table.reset() 
        self.dep_table.reset()
        self.reg_track_table.reset()

        return 

    def check_warp_usage(self, warp_usage):
        &#34;&#34;&#34;Return whether the available slots in the warp table is sufficient 
        to accomodate a new thread block 
        &#34;&#34;&#34;
        new_active_warps = self.num_active_warps + warp_usage 
        if new_active_warps &gt; self.config[&#34;max_num_warp_per_subcore&#34;]:
            return False 
        return True 

    def check_reg_usage(self, reg_usage_in_bytes):
        &#34;&#34;&#34;Returen whether the available amount of register file is sufficient
        to accomodate a new thread block 
        &#34;&#34;&#34;
        new_base_ptr = self.reg_base_ptr + reg_usage_in_bytes 
        if new_base_ptr &gt; self.config[&#34;subcore_reg_file_size&#34;]:
            return False 
        return True 

    def _load_from_icache(self, entry_id, pc):
        &#34;&#34;&#34;This function loads the instruction from the instruction cache and 
        fill in the corresponding entry of the fetch table. 

        Args:
            entry_id: the position of the entry in the fetch table
            pc: the program counter of the instruction 
        &#34;&#34;&#34;
        req = InstrLoadReq(
            subcore_id=self.subcore_id, entry_id=entry_id, pc=pc
        )
        yield self.core.icache.load_req_queque.put(req)
        self.log.debug(
            &#34;{loc} at {time_stamp} cycle: Issue load for the &#34;
            &#34;instr with PC={pc} from the entry {entry_id}&#34;.format(
                loc=self._loc_str, time_stamp=self.env.now, pc=pc, 
                entry_id=entry_id
            )
        )

        resp = yield self.core.icache.load_resp_queue.get(
            lambda x: ((x.subcore_id == self.subcore_id) 
                       and (x.entry_id == entry_id) and (x.pc == pc)) 
        )
        self.log.debug(
            &#34;{loc} at {time_stamp} cycle: Get the instruction &#34;
            &#34;with PC={pc} for the entry {entry_id}&#34;.format(
                loc=self._loc_str, time_stamp=self.env.now,
                pc=pc, entry_id=entry_id,
            )
        )

        self.warp_pipeline_table.entry[entry_id].instr = resp.instr 
        self.warp_pipeline_table.entry[entry_id].valid = True 

        return 

    def _need_fetch_stall(self, instr):
        &#34;&#34;&#34;Check the fetch stage needs to be stalled waiting for the execution
        of the current instruction. We will stall the fetch stage on any 
        control flow instructions or synchronization instructions. 

        Args:
            instr: the instruction passed to be checked. 

        Returns:
            A boolean value, True or False, to indicate whether the fetch stage
                needs to be stalled. 
        &#34;&#34;&#34;
        # Check whether it is a control flow instruction 
        if &#34;dst_pc&#34; in instr.metadata:
            return True 
        
        # Check whether it is a barrier instruction 
        if &#34;bar_id&#34; in instr.metadata: 
            return True 

        return False 

    def _fetch_and_decode(self):
        &#34;&#34;&#34;This function executes the fetch and decode stages of the subcore 
        &#34;&#34;&#34;
        while True:
            start_exec = yield self.start_exec_cmd.get() 
            assert start_exec == &#34;start&#34;, &#34;Unrecognized &#34; \
                &#34;commands: {}&#34;.format(start_exec) 

            curr_ptr = 0
            while True:
                # Step 1: check the exit condition
                all_finish = self.warp_pipeline_table\
                    .check_all_finished(self.num_active_warps)
                if all_finish is True:
                    break 

                curr_entry = deepcopy(self.warp_pipeline_table.entry[curr_ptr])

                # Step 2: skip the current warp if it is finished 
                if curr_entry.warp_finished:
                    curr_ptr = (curr_ptr + 1) % self.num_active_warps 
                    yield self.env.timeout(1 * self.clock_unit)
                    continue 

                # Step 3: check whether the current instruction is valid
                if not curr_entry.valid: 
                    if not curr_entry.issued_to_icache: 
                        self.warp_pipeline_table.entry[curr_ptr]\
                            .issued_to_icache = True
                        self.env.process(
                            self._load_from_icache(curr_ptr, curr_entry.pc)
                        )
                        curr_ptr = (curr_ptr + 1) % self.num_active_warps 

                    yield self.env.timeout(1 * self.clock_unit)
                    continue 

                # self.log.debug(&#34;{loc}: Entry {entry_id} got a valid &#34; \
                #        &#34;instruction with pc={pc}&#34;.format(
                #            loc=self._loc_str, 
                #            entry_id=curr_ptr, 
                #            pc=curr_entry.pc
                #        )
                #    )

                # Step 4: push into the next stage if resources are available 
                if not curr_entry.issued_to_decode:
                    if self.num_free_decode_buffer_slots[curr_ptr] &gt; 0:
                        self.num_free_decode_buffer_slots[curr_ptr] = (
                            self.num_free_decode_buffer_slots[curr_ptr] - 1
                        )
                        pc = deepcopy(curr_entry.pc)
                        simt_mask = deepcopy(
                            self.stack_table.entry[curr_ptr].get_simt_mask() 
                        )
                        yield self.decode_buffer[curr_ptr].put(
                            (pc, simt_mask, curr_entry.instr)
                        ) 
                        self.warp_pipeline_table.entry[
                            curr_ptr].issued_to_decode = True 
                    else:
                        if curr_entry.skip_resource_contention: 
                            self.warp_pipeline_table.entry[
                                curr_ptr].skip_resource_contention = False 
                            curr_ptr = (curr_ptr + 1) % self.num_active_warps 
                        yield self.env.timeout(1 * self.clock_unit) 

                    continue 

                # Step 5: stall the fetch stage if needed 
                if self._need_fetch_stall(curr_entry.instr):
                    if not curr_entry.executed:
                        curr_ptr = (curr_ptr + 1) % self.num_active_warps 

                        yield self.env.timeout(1 * self.clock_unit) 
                        continue 

                # Step 6: check the SIMT stack to get the correct next PC
                next_pc = curr_entry.next_pc 
                while self.stack_table.entry[curr_ptr].check_converge(next_pc):
                    self.stack_table.entry[curr_ptr].pop() 
                    top_entry = self.stack_table.entry[curr_ptr].top()
                    next_pc = top_entry[1] 
                    yield self.env.timeout(1 * self.clock_unit)

                if next_pc &gt;= self.warp_info_table.entry[curr_ptr].prog_length:
                    self.warp_pipeline_table\
                        .entry[curr_ptr].warp_finished = True 

                    yield self.env.timeout(1 * self.clock_unit)
                    continue 

                # Step 7: generate a new entry for the next PC
                new_warp_pipeline_table_entry = \
                    WarpPipelineTableEntry(pc=next_pc)
                self.warp_pipeline_table.entry[curr_ptr] = \
                    deepcopy(new_warp_pipeline_table_entry) 

                yield self.env.timeout(1 * self.clock_unit) 

        return

    def _issue(self, entry_id):
        &#34;&#34;&#34;This function executes the issue stage of subcore including 
        checking operand dependencies and send instructions to the next 
        stage 
        &#34;&#34;&#34;
        while True:
            instr_tuple = yield self.decode_buffer[entry_id].get()
            self.num_free_decode_buffer_slots[entry_id] += 1
            current_pc = instr_tuple[0]
            simt_mask = instr_tuple[1]
            instr = instr_tuple[2]

            self.log.debug(
                &#34;{loc} Entry {entry_id} start checking the &#34;
                &#34;dependency of {instr} at {time_stamp} cycle&#34;.format(
                    loc=self._loc_str, entry_id=entry_id,
                    instr=instr.instr_str, time_stamp=self.env.now
                )
            )

            src_ops = []
            dst_ops = []

            if &#34;pred_reg&#34; in instr.metadata:
                src_ops.append(instr.metadata[&#34;pred_reg&#34;].op_str)

            for each_op in instr.src_operands:
                if each_op.isreg():
                    src_ops.append(each_op.op_str)
            # self.log.debug(&#34;source operands: {}&#34;.format(src_ops))

            for each_op in instr.dst_operands:
                if each_op.isreg():
                    dst_ops.append(each_op.op_str) 
            # self.log.debug(&#34;destination operands: {}&#34;.format(dst_ops))

            # Check the dependency table until all dependencies are cleared 
            while True:
                yield self.env.timeout(1 * self.clock_unit)

                break_cond = True 
                
                for each_op in src_ops:
                    if not self.dep_table.entry[entry_id].check_read(each_op):
                        break_cond = False 
                        break 

                for each_op in dst_ops:
                    if not self.dep_table.entry[entry_id].check_write(each_op):
                        break_cond = False 
                        break 

                if break_cond:
                    break 

            self.log.debug(
                &#34;{loc} Entry {entry_id} finished checking the &#34;
                &#34;dependency of {instr} at {time_stamp} cycle&#34;.format(
                    loc=self._loc_str, entry_id=entry_id,
                    instr=instr.instr_str, time_stamp=self.env.now
                )
            )

            # Update the dependency table to pend other instructions 
            for each_op in src_ops:
                self.dep_table.entry[entry_id].increase_read(each_op) 

            for each_op in dst_ops:
                self.dep_table.entry[entry_id].increase_write(each_op)

            # (TODO) model a more accurate timing here for recording register 
            # dependencies
            yield self.env.timeout(1 * self.clock_unit) 

            yield self.execute_buffer.put(
                (current_pc, simt_mask, entry_id, instr)
            )
        return 

    def get_subcore_reg_addr(self, reg_prefix, reg_index, entry_id):
        &#34;&#34;&#34;This function calculates the absolute addrss of a register in the 
        register file of subcore. It also returns the size of registers with 
        the same name across threads in the whole warp.  
        
        Args:
            reg_prefix: the prefix of register name 
            reg_index: the index of the register 
            entry_id: the warp ID of this register 

        Returns:
            (reg_addr, reg_size): the stating address of this register in the 
                register file and the size of the whole register 
        &#34;&#34;&#34;
        reg_base_addr = self.warp_info_table\
            .entry[entry_id].subcore_reg_base_addr 
        prefix_reg_base_addr = (
            reg_base_addr 
            + self.warp_info_table.entry[entry_id].prog_reg_offset[reg_prefix]
        )
        reg_size = self.warp_info_table\
            .entry[entry_id].prog_reg_size[reg_prefix]
        reg_addr = prefix_reg_base_addr + reg_index * reg_size

        self.log.debug(
            &#34;{loc} Entry {entry_id} {reg_prefix}{reg_index} &#34; 
            &#34;starting from {reg_addr} with size {reg_size}&#34;.format(
                loc=self._loc_str, entry_id=entry_id, 
                reg_prefix=reg_prefix, reg_index=reg_index,
                reg_addr=reg_addr, reg_size=reg_size 
            )
        )
        return (reg_addr, reg_size)

    def get_param_value(self, param_name, entry_id):
        &#34;&#34;&#34;This function gets the value of parameters including kernel function
        arguments and shared memory parameter. 

        Args:
            param_name: the parameter name
            entry_id: the entry ID the current warp. This ID is used to locate 
                shared memory base address and offset for the dynamically 
                allocated shared memory space 

        Returns:
            param_value: the value of parameter in its corresponding type 
        &#34;&#34;&#34;
        prog_smem_offset = \
            self.warp_info_table.entry[entry_id].prog_smem_offset
        if param_name in self.core.param_dict:
            return self.core.param_dict[param_name]
        elif param_name in prog_smem_offset:
            base_addr = self.warp_info_table.entry[entry_id].smem_base_addr
            offset = (
                self.warp_info_table
                .entry[entry_id].prog_smem_offset[param_name]
            ) 
            return base_addr + offset 
        else: 
            raise NotImplementedError(
                &#34;Unknown parameter:{}&#34;.format(param_name)
            )
        return 

    def get_special_reg_value(self, reg_name, entry_id):
        &#34;&#34;&#34;This function is used to get the value of special registers storing 
        SIMT thread information, such as block ID and thread ID. 

        Args:
            reg_name: the name of special register 
            entry_id: the entry ID of the current warp so that block ID and 
                thread ID can be accurately located. 

        Returns:
            reg_value: an integer if the requested registr has the same value 
                for all threads in the same warp, or a list of values for 
                different values of threads in the same warp. 
        &#34;&#34;&#34;
        index_mapper = {&#34;z&#34;: 0, &#34;y&#34;: 1, &#34;x&#34;: 2}
        reg_prefix = reg_name.split(&#34;.&#34;)[0]
        reg_index = index_mapper[reg_name.split(&#34;.&#34;)[1]]

        if reg_prefix == &#34;%ntid&#34;:
            return self.core.block_dim[reg_index]
        elif reg_prefix == &#34;%ctaid&#34;:
            return self.warp_info_table.entry[entry_id].block_id[reg_index] 
        elif reg_prefix == &#34;%tid&#34;:
            start_id = self.warp_info_table.entry[entry_id].thread_id[reg_index]
            if reg_index != 2:
                return start_id 
            else: 
                value_list = list(range(
                    start_id, start_id + self.config[&#34;num_threads_per_warp&#34;]))
                return value_list 
        elif reg_prefix == &#34;%nctaid&#34;:
            return self.core.grid_dim[reg_index] 
        else:
            raise NotImplementedError(
                &#34;Unknown special register: {}&#34;.format(reg_name)
            )
        return 

    def _receive_bus_data(self):
        &#34;&#34;&#34;This function receives data from subcore-pg buses
        &#34;&#34;&#34;
        while True:
            packet = yield self.bus_receive_buffer.get()
            if isinstance(packet, RegMoveReq):
                self.reg_move_engine\
                    .reg_req_bus_queue.put(packet)

    def _execute(self):
        &#34;&#34;&#34;This function executes the functionality of the execute stage of 
        the subcore including reading values from registers, compute results, 
        and pass the instruction with results to the write back stage. 
        &#34;&#34;&#34;
        while True:
            instr_tuple = yield self.execute_buffer.get() 
            current_pc = instr_tuple[0]
            simt_mask = instr_tuple[1]
            entry_id = instr_tuple[2]
            instr = instr_tuple[3] 
            
            # compose an instance of instruction
            instr_entry = InstrEntry(
                log=self.log,
                config=self.config,
                instr=instr,
                simt_mask=simt_mask,
                pc=current_pc,
                subcore_id=self.subcore_id,
                warp_id=entry_id
            )
            
            # dispatch instruction to operand collector units
            opcode = instr_entry.instr.opcode.split(&#34;.&#34;)[0]
            if opcode in self.config[&#34;alu_instr&#34;]:
                # TODO offload engine should decide
                yield self.opc_fb_alu.instr_entry_queue.put(instr_entry)
            elif opcode in self.config[&#34;sfu_instr&#34;]:
                yield self.opc_sfu.instr_entry_queue.put(instr_entry)
            elif opcode in self.config[&#34;lsu_instr&#34;]:
                yield self.opc_lsu.instr_entry_queue.put(instr_entry)
            elif opcode in self.config[&#34;cfu_instr&#34;]:
                yield self.opc_cfu.instr_entry_queue.put(instr_entry)
            elif opcode in self.config[&#34;syncu_instr&#34;]:
                yield self.opc_syncu.instr_entry_queue.put(instr_entry)
            else:
                raise NotImplementedError(
                    &#34;Unsupported opcode: {}&#34;.format(opcode)
                )
        return

    def _commit(self):
        &#34;&#34;&#34;This stage executes the commit stage of the subcore including 
        writing results of destination operands to register file, release 
        the register dependency, release the instruciton stall on the fetch 
        stage, and check whether the current batch of thread blocks finishes 
        the execution. 
        &#34;&#34;&#34;
        while True:
            instr_entry = yield self.writeback_buffer.get()
            current_pc = instr_entry.pc
            simt_mask = instr_entry.simt_mask
            entry_id = instr_entry.warp_id
            instr = instr_entry.instr

            for i in range(len(instr.dst_operands)):
                dst_op = instr.dst_operands[i]
                reg_addr, reg_size = self.get_subcore_reg_addr(
                    dst_op.reg_prefix, dst_op.reg_index, entry_id
                )

                if simt_mask &gt; 0:
                    # Write results back to register file
                    operand_write_req = OperandWriteReq(
                        base_reg_addr=reg_addr,
                        total_reg_size=reg_size,
                        simt_mask=simt_mask,
                        data=instr_entry.dst_values[i]
                    )
                    self.local_regfile_write_port_id_commit = \
                        (self.local_regfile_write_port_id_commit + 1) \
                        % self.config[&#34;num_fb_commit_port&#34;]
                    regfile_write_port_id = \
                        self.base_regfile_write_port_id_commit \
                        + self.local_regfile_write_port_id_commit
                    yield self.rf_io_interface\
                        .write_req_queue[regfile_write_port_id]\
                        .put(operand_write_req)

                    _ = yield self.rf_io_interface.write_resp_queue.get(
                        lambda x: (x.base_reg_addr == reg_addr
                                   and x.total_reg_size == reg_size)
                    )
                
                # Release the dependency in the dependency table
                self.dep_table.entry[entry_id].decrease_write(dst_op.op_str)
                
                # Update register tracking table
                # TODO: support near-bank writeback
                self.reg_track_table.entry[entry_id].write_update(
                    op_str=dst_op.op_str,
                    reg_file_type=&#34;far-bank&#34;
                )

            assert instr_entry.processed is True, &#34;Can not pass an &#34; \
                &#34;unprocessed instruction to the writeback stage&#34;
            
            if current_pc == self.warp_pipeline_table.entry[entry_id].pc:
                self.warp_pipeline_table.entry[entry_id].executed = True 

            prog_length = \
                self.warp_info_table.entry[entry_id].prog_length
            if (current_pc + 1) == prog_length:
                self.warp_info_table.entry[entry_id].warp_finished = True
                assert instr.opcode == &#34;ret&#34;, &#34;The last instruction is not&#34; \
                    &#34;the return instruction!&#34;

                all_finish = \
                    self.warp_info_table\
                    .check_all_finished(self.num_active_warps)
                if all_finish is True:
                    yield self.finish_exec_resp.put(&#34;success&#34;) 

        return </code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="simulator.subcore.Subcore"><code class="flex name class">
<span>class <span class="ident">Subcore</span></span>
<span>(</span><span>subcore_id, env, config, log, core)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Subcore:

    def __init__(self, subcore_id, env, config, log, core):
        self.subcore_id = subcore_id 
        self.env = env 
        self.config = config 
        self.log = log
        self.core = core

        self.clock_unit = deepcopy(core.clock_unit) 
        self._loc_str = &#34;Processor ID: {proc_id}, Core ID: {core_id}, &#34; \
            &#34;Subcore ID: {subcore_id}&#34;.format(
                proc_id=self.core.processor.proc_id,
                core_id=self.core.core_id,
                subcore_id=self.subcore_id, 
            )

        self.start_exec_cmd = simpy.Store(env, capacity=1)
        self.finish_exec_resp = simpy.Store(env, capacity=1) 

        self.num_active_warps = 0
        self.warp_info_table = WarpInfoTable(config=self.config, log=self.log) 
        self.warp_pipeline_table = \
            WarpPipelineTable(config=self.config, log=self.log)
        self.stack_table = StackTable(config=self.config, log=self.log)
        self.dep_table = DepTable(config=self.config, log=self.log)

        self.reg_file = RegisterFile(
            env=env, 
            log=log, 
            config=self.config,
            clock_unit=self.clock_unit,  
            reg_file_type=&#34;far-bank&#34;
        )

        self.reg_track_table = RegTrackTable(
            config=self.config,
            log=self.log,
            reg_file=self.reg_file
        )

        self.rf_io_interface = RegFileOperandIOInterface(
            env=self.env,
            log=self.log,
            config=self.config,
            clock_unit=self.clock_unit,
            reg_file=self.reg_file,
            interface_type=&#34;far-bank&#34;,
        )

        self.reg_move_engine = RegMoveEngine(
            env=self.env,
            log=self.log,
            config=self.config,
            clock_unit=self.clock_unit,
            backend=self,
            regfile_io_interface=self.rf_io_interface,
            bus_arbiter=self.core.subcore_pg_bus_arbiter,
            engine_type=&#34;fb_reg_move&#34;
        )

        self.instr_offload_engine = InstrOffloadEngine(
            env=self.env,
            config=self.config,
            log=self.log,
            reg_move_engine=self.reg_move_engine,
            subcore=self
        )

        # TODO make this port assignment more accurate
        # currently round-robin
        self.local_regfile_write_port_id_commit = 0
        self.base_regfile_write_port_id_commit = \
            self.config[&#34;base_regfile_write_port_id_fb_commit&#34;]

        self.decode_buffer = []
        self.num_free_decode_buffer_slots = []
        for i in range(self.config[&#34;max_num_warp_per_subcore&#34;]):
            self.decode_buffer.append(simpy.Store(env))
            self.num_free_decode_buffer_slots.append(
                self.config[&#34;decode_buffer_size&#34;])

        self.execute_buffer = simpy.Store(
            env, capacity=(self.config[&#34;subcore_execute_buffer_size&#34;])
        )

        self.writeback_buffer = simpy.Store(
            env, capacity=self.config[&#34;subcore_writeback_buffer_size&#34;]
        )

        self.sync_buffer = simpy.Store(
            env, capacity=self.config[&#34;max_num_warp_per_subcore&#34;]
        )

        self.bus_receive_buffer = simpy.Store(
            env, capacity=self.config[&#34;subcore_bus_receive_buffer_size&#34;]
        )

        self.reg_base_ptr = 0

        # Execution Stage
        # arithemtic logic unit
        self.fb_alu = ArithmeticLogicUnit(
            env=self.env,
            log=self.log,
            config=self.config,
            clock_unit=self.clock_unit,
            backend=self,
            alu_type=&#34;far-bank&#34;
        )
        self.opc_fb_alu = OperandCollector(
            env=self.env,
            log=self.log,
            config=self.config,
            clock_unit=self.clock_unit,
            backend=self,
            regfile_io_interface=self.rf_io_interface,
            execution_unit=self.fb_alu,
            opc_type=&#34;fb_alu&#34;
        )
        
        # special function unit
        self.sfu = SpecialFunctionUnit(
            env=self.env,
            log=self.log,
            config=self.config,
            clock_unit=self.clock_unit,
            subcore=self
        )
        self.opc_sfu = OperandCollector(
            env=self.env,
            log=self.log,
            config=self.config,
            clock_unit=self.clock_unit,
            backend=self,
            regfile_io_interface=self.rf_io_interface,
            execution_unit=self.sfu,
            opc_type=&#34;sfu&#34;
        )

        # load-store unit
        self.lsu = LoadStoreUnit(
            env=self.env,
            log=self.log,
            config=self.config,
            clock_unit=self.clock_unit,
            subcore=self
        )
        self.opc_lsu = OperandCollector(
            env=self.env,
            log=self.log,
            config=self.config,
            clock_unit=self.clock_unit,
            backend=self,
            regfile_io_interface=self.rf_io_interface,
            execution_unit=self.lsu,
            opc_type=&#34;lsu&#34;
        )

        # control-flow unit
        self.cfu = ControlFlowUnit(
            env=self.env,
            log=self.log,
            config=self.config,
            clock_unit=self.clock_unit,
            subcore=self
        )
        self.opc_cfu = OperandCollector(
            env=self.env,
            log=self.log,
            config=self.config,
            clock_unit=self.clock_unit,
            backend=self,
            regfile_io_interface=self.rf_io_interface,
            execution_unit=self.cfu,
            opc_type=&#34;cfu&#34;
        )

        # synchronization unit
        self.syncu = SynchronizationUnit(
            env=self.env,
            log=self.log,
            config=self.config,
            clock_unit=self.clock_unit,
            subcore=self
        )
        self.opc_syncu = OperandCollector(
            env=self.env,
            log=self.log,
            config=self.config,
            clock_unit=self.clock_unit,
            backend=self,
            regfile_io_interface=self.rf_io_interface,
            execution_unit=self.syncu,
            opc_type=&#34;syncu&#34;
        )

        # Spawn a process for the fetch and decode subcore stages
        self.env.process(self._fetch_and_decode())

        # Spawn processes for the issue subcore stage
        for i in range(self.config[&#34;max_num_warp_per_subcore&#34;]):
            self.env.process(self._issue(entry_id=i))

        # Spawn a process for the execute subcore stage 
        self.env.process(self._execute())

        # Spawn a process for the commit subcore stage 
        self.env.process(self._commit())

        # Spawn a process to receive data from the bus
        self.env.process(self._receive_bus_data())
        return 

    def reset_status(self):
        &#34;&#34;&#34;Reset hardware status of subcores.This function is usually used 
        to reset subcore status between different calls of executing thread 
        blocks. 
        &#34;&#34;&#34;
        self.num_active_warps = 0
        self.reg_base_ptr = 0

        # Reset the tables in the subcore  
        self.warp_info_table.reset()
        self.warp_pipeline_table.reset() 
        self.stack_table.reset() 
        self.dep_table.reset()
        self.reg_track_table.reset()

        return 

    def check_warp_usage(self, warp_usage):
        &#34;&#34;&#34;Return whether the available slots in the warp table is sufficient 
        to accomodate a new thread block 
        &#34;&#34;&#34;
        new_active_warps = self.num_active_warps + warp_usage 
        if new_active_warps &gt; self.config[&#34;max_num_warp_per_subcore&#34;]:
            return False 
        return True 

    def check_reg_usage(self, reg_usage_in_bytes):
        &#34;&#34;&#34;Returen whether the available amount of register file is sufficient
        to accomodate a new thread block 
        &#34;&#34;&#34;
        new_base_ptr = self.reg_base_ptr + reg_usage_in_bytes 
        if new_base_ptr &gt; self.config[&#34;subcore_reg_file_size&#34;]:
            return False 
        return True 

    def _load_from_icache(self, entry_id, pc):
        &#34;&#34;&#34;This function loads the instruction from the instruction cache and 
        fill in the corresponding entry of the fetch table. 

        Args:
            entry_id: the position of the entry in the fetch table
            pc: the program counter of the instruction 
        &#34;&#34;&#34;
        req = InstrLoadReq(
            subcore_id=self.subcore_id, entry_id=entry_id, pc=pc
        )
        yield self.core.icache.load_req_queque.put(req)
        self.log.debug(
            &#34;{loc} at {time_stamp} cycle: Issue load for the &#34;
            &#34;instr with PC={pc} from the entry {entry_id}&#34;.format(
                loc=self._loc_str, time_stamp=self.env.now, pc=pc, 
                entry_id=entry_id
            )
        )

        resp = yield self.core.icache.load_resp_queue.get(
            lambda x: ((x.subcore_id == self.subcore_id) 
                       and (x.entry_id == entry_id) and (x.pc == pc)) 
        )
        self.log.debug(
            &#34;{loc} at {time_stamp} cycle: Get the instruction &#34;
            &#34;with PC={pc} for the entry {entry_id}&#34;.format(
                loc=self._loc_str, time_stamp=self.env.now,
                pc=pc, entry_id=entry_id,
            )
        )

        self.warp_pipeline_table.entry[entry_id].instr = resp.instr 
        self.warp_pipeline_table.entry[entry_id].valid = True 

        return 

    def _need_fetch_stall(self, instr):
        &#34;&#34;&#34;Check the fetch stage needs to be stalled waiting for the execution
        of the current instruction. We will stall the fetch stage on any 
        control flow instructions or synchronization instructions. 

        Args:
            instr: the instruction passed to be checked. 

        Returns:
            A boolean value, True or False, to indicate whether the fetch stage
                needs to be stalled. 
        &#34;&#34;&#34;
        # Check whether it is a control flow instruction 
        if &#34;dst_pc&#34; in instr.metadata:
            return True 
        
        # Check whether it is a barrier instruction 
        if &#34;bar_id&#34; in instr.metadata: 
            return True 

        return False 

    def _fetch_and_decode(self):
        &#34;&#34;&#34;This function executes the fetch and decode stages of the subcore 
        &#34;&#34;&#34;
        while True:
            start_exec = yield self.start_exec_cmd.get() 
            assert start_exec == &#34;start&#34;, &#34;Unrecognized &#34; \
                &#34;commands: {}&#34;.format(start_exec) 

            curr_ptr = 0
            while True:
                # Step 1: check the exit condition
                all_finish = self.warp_pipeline_table\
                    .check_all_finished(self.num_active_warps)
                if all_finish is True:
                    break 

                curr_entry = deepcopy(self.warp_pipeline_table.entry[curr_ptr])

                # Step 2: skip the current warp if it is finished 
                if curr_entry.warp_finished:
                    curr_ptr = (curr_ptr + 1) % self.num_active_warps 
                    yield self.env.timeout(1 * self.clock_unit)
                    continue 

                # Step 3: check whether the current instruction is valid
                if not curr_entry.valid: 
                    if not curr_entry.issued_to_icache: 
                        self.warp_pipeline_table.entry[curr_ptr]\
                            .issued_to_icache = True
                        self.env.process(
                            self._load_from_icache(curr_ptr, curr_entry.pc)
                        )
                        curr_ptr = (curr_ptr + 1) % self.num_active_warps 

                    yield self.env.timeout(1 * self.clock_unit)
                    continue 

                # self.log.debug(&#34;{loc}: Entry {entry_id} got a valid &#34; \
                #        &#34;instruction with pc={pc}&#34;.format(
                #            loc=self._loc_str, 
                #            entry_id=curr_ptr, 
                #            pc=curr_entry.pc
                #        )
                #    )

                # Step 4: push into the next stage if resources are available 
                if not curr_entry.issued_to_decode:
                    if self.num_free_decode_buffer_slots[curr_ptr] &gt; 0:
                        self.num_free_decode_buffer_slots[curr_ptr] = (
                            self.num_free_decode_buffer_slots[curr_ptr] - 1
                        )
                        pc = deepcopy(curr_entry.pc)
                        simt_mask = deepcopy(
                            self.stack_table.entry[curr_ptr].get_simt_mask() 
                        )
                        yield self.decode_buffer[curr_ptr].put(
                            (pc, simt_mask, curr_entry.instr)
                        ) 
                        self.warp_pipeline_table.entry[
                            curr_ptr].issued_to_decode = True 
                    else:
                        if curr_entry.skip_resource_contention: 
                            self.warp_pipeline_table.entry[
                                curr_ptr].skip_resource_contention = False 
                            curr_ptr = (curr_ptr + 1) % self.num_active_warps 
                        yield self.env.timeout(1 * self.clock_unit) 

                    continue 

                # Step 5: stall the fetch stage if needed 
                if self._need_fetch_stall(curr_entry.instr):
                    if not curr_entry.executed:
                        curr_ptr = (curr_ptr + 1) % self.num_active_warps 

                        yield self.env.timeout(1 * self.clock_unit) 
                        continue 

                # Step 6: check the SIMT stack to get the correct next PC
                next_pc = curr_entry.next_pc 
                while self.stack_table.entry[curr_ptr].check_converge(next_pc):
                    self.stack_table.entry[curr_ptr].pop() 
                    top_entry = self.stack_table.entry[curr_ptr].top()
                    next_pc = top_entry[1] 
                    yield self.env.timeout(1 * self.clock_unit)

                if next_pc &gt;= self.warp_info_table.entry[curr_ptr].prog_length:
                    self.warp_pipeline_table\
                        .entry[curr_ptr].warp_finished = True 

                    yield self.env.timeout(1 * self.clock_unit)
                    continue 

                # Step 7: generate a new entry for the next PC
                new_warp_pipeline_table_entry = \
                    WarpPipelineTableEntry(pc=next_pc)
                self.warp_pipeline_table.entry[curr_ptr] = \
                    deepcopy(new_warp_pipeline_table_entry) 

                yield self.env.timeout(1 * self.clock_unit) 

        return

    def _issue(self, entry_id):
        &#34;&#34;&#34;This function executes the issue stage of subcore including 
        checking operand dependencies and send instructions to the next 
        stage 
        &#34;&#34;&#34;
        while True:
            instr_tuple = yield self.decode_buffer[entry_id].get()
            self.num_free_decode_buffer_slots[entry_id] += 1
            current_pc = instr_tuple[0]
            simt_mask = instr_tuple[1]
            instr = instr_tuple[2]

            self.log.debug(
                &#34;{loc} Entry {entry_id} start checking the &#34;
                &#34;dependency of {instr} at {time_stamp} cycle&#34;.format(
                    loc=self._loc_str, entry_id=entry_id,
                    instr=instr.instr_str, time_stamp=self.env.now
                )
            )

            src_ops = []
            dst_ops = []

            if &#34;pred_reg&#34; in instr.metadata:
                src_ops.append(instr.metadata[&#34;pred_reg&#34;].op_str)

            for each_op in instr.src_operands:
                if each_op.isreg():
                    src_ops.append(each_op.op_str)
            # self.log.debug(&#34;source operands: {}&#34;.format(src_ops))

            for each_op in instr.dst_operands:
                if each_op.isreg():
                    dst_ops.append(each_op.op_str) 
            # self.log.debug(&#34;destination operands: {}&#34;.format(dst_ops))

            # Check the dependency table until all dependencies are cleared 
            while True:
                yield self.env.timeout(1 * self.clock_unit)

                break_cond = True 
                
                for each_op in src_ops:
                    if not self.dep_table.entry[entry_id].check_read(each_op):
                        break_cond = False 
                        break 

                for each_op in dst_ops:
                    if not self.dep_table.entry[entry_id].check_write(each_op):
                        break_cond = False 
                        break 

                if break_cond:
                    break 

            self.log.debug(
                &#34;{loc} Entry {entry_id} finished checking the &#34;
                &#34;dependency of {instr} at {time_stamp} cycle&#34;.format(
                    loc=self._loc_str, entry_id=entry_id,
                    instr=instr.instr_str, time_stamp=self.env.now
                )
            )

            # Update the dependency table to pend other instructions 
            for each_op in src_ops:
                self.dep_table.entry[entry_id].increase_read(each_op) 

            for each_op in dst_ops:
                self.dep_table.entry[entry_id].increase_write(each_op)

            # (TODO) model a more accurate timing here for recording register 
            # dependencies
            yield self.env.timeout(1 * self.clock_unit) 

            yield self.execute_buffer.put(
                (current_pc, simt_mask, entry_id, instr)
            )
        return 

    def get_subcore_reg_addr(self, reg_prefix, reg_index, entry_id):
        &#34;&#34;&#34;This function calculates the absolute addrss of a register in the 
        register file of subcore. It also returns the size of registers with 
        the same name across threads in the whole warp.  
        
        Args:
            reg_prefix: the prefix of register name 
            reg_index: the index of the register 
            entry_id: the warp ID of this register 

        Returns:
            (reg_addr, reg_size): the stating address of this register in the 
                register file and the size of the whole register 
        &#34;&#34;&#34;
        reg_base_addr = self.warp_info_table\
            .entry[entry_id].subcore_reg_base_addr 
        prefix_reg_base_addr = (
            reg_base_addr 
            + self.warp_info_table.entry[entry_id].prog_reg_offset[reg_prefix]
        )
        reg_size = self.warp_info_table\
            .entry[entry_id].prog_reg_size[reg_prefix]
        reg_addr = prefix_reg_base_addr + reg_index * reg_size

        self.log.debug(
            &#34;{loc} Entry {entry_id} {reg_prefix}{reg_index} &#34; 
            &#34;starting from {reg_addr} with size {reg_size}&#34;.format(
                loc=self._loc_str, entry_id=entry_id, 
                reg_prefix=reg_prefix, reg_index=reg_index,
                reg_addr=reg_addr, reg_size=reg_size 
            )
        )
        return (reg_addr, reg_size)

    def get_param_value(self, param_name, entry_id):
        &#34;&#34;&#34;This function gets the value of parameters including kernel function
        arguments and shared memory parameter. 

        Args:
            param_name: the parameter name
            entry_id: the entry ID the current warp. This ID is used to locate 
                shared memory base address and offset for the dynamically 
                allocated shared memory space 

        Returns:
            param_value: the value of parameter in its corresponding type 
        &#34;&#34;&#34;
        prog_smem_offset = \
            self.warp_info_table.entry[entry_id].prog_smem_offset
        if param_name in self.core.param_dict:
            return self.core.param_dict[param_name]
        elif param_name in prog_smem_offset:
            base_addr = self.warp_info_table.entry[entry_id].smem_base_addr
            offset = (
                self.warp_info_table
                .entry[entry_id].prog_smem_offset[param_name]
            ) 
            return base_addr + offset 
        else: 
            raise NotImplementedError(
                &#34;Unknown parameter:{}&#34;.format(param_name)
            )
        return 

    def get_special_reg_value(self, reg_name, entry_id):
        &#34;&#34;&#34;This function is used to get the value of special registers storing 
        SIMT thread information, such as block ID and thread ID. 

        Args:
            reg_name: the name of special register 
            entry_id: the entry ID of the current warp so that block ID and 
                thread ID can be accurately located. 

        Returns:
            reg_value: an integer if the requested registr has the same value 
                for all threads in the same warp, or a list of values for 
                different values of threads in the same warp. 
        &#34;&#34;&#34;
        index_mapper = {&#34;z&#34;: 0, &#34;y&#34;: 1, &#34;x&#34;: 2}
        reg_prefix = reg_name.split(&#34;.&#34;)[0]
        reg_index = index_mapper[reg_name.split(&#34;.&#34;)[1]]

        if reg_prefix == &#34;%ntid&#34;:
            return self.core.block_dim[reg_index]
        elif reg_prefix == &#34;%ctaid&#34;:
            return self.warp_info_table.entry[entry_id].block_id[reg_index] 
        elif reg_prefix == &#34;%tid&#34;:
            start_id = self.warp_info_table.entry[entry_id].thread_id[reg_index]
            if reg_index != 2:
                return start_id 
            else: 
                value_list = list(range(
                    start_id, start_id + self.config[&#34;num_threads_per_warp&#34;]))
                return value_list 
        elif reg_prefix == &#34;%nctaid&#34;:
            return self.core.grid_dim[reg_index] 
        else:
            raise NotImplementedError(
                &#34;Unknown special register: {}&#34;.format(reg_name)
            )
        return 

    def _receive_bus_data(self):
        &#34;&#34;&#34;This function receives data from subcore-pg buses
        &#34;&#34;&#34;
        while True:
            packet = yield self.bus_receive_buffer.get()
            if isinstance(packet, RegMoveReq):
                self.reg_move_engine\
                    .reg_req_bus_queue.put(packet)

    def _execute(self):
        &#34;&#34;&#34;This function executes the functionality of the execute stage of 
        the subcore including reading values from registers, compute results, 
        and pass the instruction with results to the write back stage. 
        &#34;&#34;&#34;
        while True:
            instr_tuple = yield self.execute_buffer.get() 
            current_pc = instr_tuple[0]
            simt_mask = instr_tuple[1]
            entry_id = instr_tuple[2]
            instr = instr_tuple[3] 
            
            # compose an instance of instruction
            instr_entry = InstrEntry(
                log=self.log,
                config=self.config,
                instr=instr,
                simt_mask=simt_mask,
                pc=current_pc,
                subcore_id=self.subcore_id,
                warp_id=entry_id
            )
            
            # dispatch instruction to operand collector units
            opcode = instr_entry.instr.opcode.split(&#34;.&#34;)[0]
            if opcode in self.config[&#34;alu_instr&#34;]:
                # TODO offload engine should decide
                yield self.opc_fb_alu.instr_entry_queue.put(instr_entry)
            elif opcode in self.config[&#34;sfu_instr&#34;]:
                yield self.opc_sfu.instr_entry_queue.put(instr_entry)
            elif opcode in self.config[&#34;lsu_instr&#34;]:
                yield self.opc_lsu.instr_entry_queue.put(instr_entry)
            elif opcode in self.config[&#34;cfu_instr&#34;]:
                yield self.opc_cfu.instr_entry_queue.put(instr_entry)
            elif opcode in self.config[&#34;syncu_instr&#34;]:
                yield self.opc_syncu.instr_entry_queue.put(instr_entry)
            else:
                raise NotImplementedError(
                    &#34;Unsupported opcode: {}&#34;.format(opcode)
                )
        return

    def _commit(self):
        &#34;&#34;&#34;This stage executes the commit stage of the subcore including 
        writing results of destination operands to register file, release 
        the register dependency, release the instruciton stall on the fetch 
        stage, and check whether the current batch of thread blocks finishes 
        the execution. 
        &#34;&#34;&#34;
        while True:
            instr_entry = yield self.writeback_buffer.get()
            current_pc = instr_entry.pc
            simt_mask = instr_entry.simt_mask
            entry_id = instr_entry.warp_id
            instr = instr_entry.instr

            for i in range(len(instr.dst_operands)):
                dst_op = instr.dst_operands[i]
                reg_addr, reg_size = self.get_subcore_reg_addr(
                    dst_op.reg_prefix, dst_op.reg_index, entry_id
                )

                if simt_mask &gt; 0:
                    # Write results back to register file
                    operand_write_req = OperandWriteReq(
                        base_reg_addr=reg_addr,
                        total_reg_size=reg_size,
                        simt_mask=simt_mask,
                        data=instr_entry.dst_values[i]
                    )
                    self.local_regfile_write_port_id_commit = \
                        (self.local_regfile_write_port_id_commit + 1) \
                        % self.config[&#34;num_fb_commit_port&#34;]
                    regfile_write_port_id = \
                        self.base_regfile_write_port_id_commit \
                        + self.local_regfile_write_port_id_commit
                    yield self.rf_io_interface\
                        .write_req_queue[regfile_write_port_id]\
                        .put(operand_write_req)

                    _ = yield self.rf_io_interface.write_resp_queue.get(
                        lambda x: (x.base_reg_addr == reg_addr
                                   and x.total_reg_size == reg_size)
                    )
                
                # Release the dependency in the dependency table
                self.dep_table.entry[entry_id].decrease_write(dst_op.op_str)
                
                # Update register tracking table
                # TODO: support near-bank writeback
                self.reg_track_table.entry[entry_id].write_update(
                    op_str=dst_op.op_str,
                    reg_file_type=&#34;far-bank&#34;
                )

            assert instr_entry.processed is True, &#34;Can not pass an &#34; \
                &#34;unprocessed instruction to the writeback stage&#34;
            
            if current_pc == self.warp_pipeline_table.entry[entry_id].pc:
                self.warp_pipeline_table.entry[entry_id].executed = True 

            prog_length = \
                self.warp_info_table.entry[entry_id].prog_length
            if (current_pc + 1) == prog_length:
                self.warp_info_table.entry[entry_id].warp_finished = True
                assert instr.opcode == &#34;ret&#34;, &#34;The last instruction is not&#34; \
                    &#34;the return instruction!&#34;

                all_finish = \
                    self.warp_info_table\
                    .check_all_finished(self.num_active_warps)
                if all_finish is True:
                    yield self.finish_exec_resp.put(&#34;success&#34;) 

        return </code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="simulator.subcore.Subcore.check_reg_usage"><code class="name flex">
<span>def <span class="ident">check_reg_usage</span></span>(<span>self, reg_usage_in_bytes)</span>
</code></dt>
<dd>
<div class="desc"><p>Returen whether the available amount of register file is sufficient
to accomodate a new thread block</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def check_reg_usage(self, reg_usage_in_bytes):
    &#34;&#34;&#34;Returen whether the available amount of register file is sufficient
    to accomodate a new thread block 
    &#34;&#34;&#34;
    new_base_ptr = self.reg_base_ptr + reg_usage_in_bytes 
    if new_base_ptr &gt; self.config[&#34;subcore_reg_file_size&#34;]:
        return False 
    return True </code></pre>
</details>
</dd>
<dt id="simulator.subcore.Subcore.check_warp_usage"><code class="name flex">
<span>def <span class="ident">check_warp_usage</span></span>(<span>self, warp_usage)</span>
</code></dt>
<dd>
<div class="desc"><p>Return whether the available slots in the warp table is sufficient
to accomodate a new thread block</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def check_warp_usage(self, warp_usage):
    &#34;&#34;&#34;Return whether the available slots in the warp table is sufficient 
    to accomodate a new thread block 
    &#34;&#34;&#34;
    new_active_warps = self.num_active_warps + warp_usage 
    if new_active_warps &gt; self.config[&#34;max_num_warp_per_subcore&#34;]:
        return False 
    return True </code></pre>
</details>
</dd>
<dt id="simulator.subcore.Subcore.get_param_value"><code class="name flex">
<span>def <span class="ident">get_param_value</span></span>(<span>self, param_name, entry_id)</span>
</code></dt>
<dd>
<div class="desc"><p>This function gets the value of parameters including kernel function
arguments and shared memory parameter. </p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>param_name</code></strong></dt>
<dd>the parameter name</dd>
<dt><strong><code>entry_id</code></strong></dt>
<dd>the entry ID the current warp. This ID is used to locate
shared memory base address and offset for the dynamically
allocated shared memory space </dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>param_value</code></dt>
<dd>the value of parameter in its corresponding type</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_param_value(self, param_name, entry_id):
    &#34;&#34;&#34;This function gets the value of parameters including kernel function
    arguments and shared memory parameter. 

    Args:
        param_name: the parameter name
        entry_id: the entry ID the current warp. This ID is used to locate 
            shared memory base address and offset for the dynamically 
            allocated shared memory space 

    Returns:
        param_value: the value of parameter in its corresponding type 
    &#34;&#34;&#34;
    prog_smem_offset = \
        self.warp_info_table.entry[entry_id].prog_smem_offset
    if param_name in self.core.param_dict:
        return self.core.param_dict[param_name]
    elif param_name in prog_smem_offset:
        base_addr = self.warp_info_table.entry[entry_id].smem_base_addr
        offset = (
            self.warp_info_table
            .entry[entry_id].prog_smem_offset[param_name]
        ) 
        return base_addr + offset 
    else: 
        raise NotImplementedError(
            &#34;Unknown parameter:{}&#34;.format(param_name)
        )
    return </code></pre>
</details>
</dd>
<dt id="simulator.subcore.Subcore.get_special_reg_value"><code class="name flex">
<span>def <span class="ident">get_special_reg_value</span></span>(<span>self, reg_name, entry_id)</span>
</code></dt>
<dd>
<div class="desc"><p>This function is used to get the value of special registers storing
SIMT thread information, such as block ID and thread ID. </p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>reg_name</code></strong></dt>
<dd>the name of special register </dd>
<dt><strong><code>entry_id</code></strong></dt>
<dd>the entry ID of the current warp so that block ID and
thread ID can be accurately located. </dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>reg_value</code></dt>
<dd>an integer if the requested registr has the same value
for all threads in the same warp, or a list of values for
different values of threads in the same warp.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_special_reg_value(self, reg_name, entry_id):
    &#34;&#34;&#34;This function is used to get the value of special registers storing 
    SIMT thread information, such as block ID and thread ID. 

    Args:
        reg_name: the name of special register 
        entry_id: the entry ID of the current warp so that block ID and 
            thread ID can be accurately located. 

    Returns:
        reg_value: an integer if the requested registr has the same value 
            for all threads in the same warp, or a list of values for 
            different values of threads in the same warp. 
    &#34;&#34;&#34;
    index_mapper = {&#34;z&#34;: 0, &#34;y&#34;: 1, &#34;x&#34;: 2}
    reg_prefix = reg_name.split(&#34;.&#34;)[0]
    reg_index = index_mapper[reg_name.split(&#34;.&#34;)[1]]

    if reg_prefix == &#34;%ntid&#34;:
        return self.core.block_dim[reg_index]
    elif reg_prefix == &#34;%ctaid&#34;:
        return self.warp_info_table.entry[entry_id].block_id[reg_index] 
    elif reg_prefix == &#34;%tid&#34;:
        start_id = self.warp_info_table.entry[entry_id].thread_id[reg_index]
        if reg_index != 2:
            return start_id 
        else: 
            value_list = list(range(
                start_id, start_id + self.config[&#34;num_threads_per_warp&#34;]))
            return value_list 
    elif reg_prefix == &#34;%nctaid&#34;:
        return self.core.grid_dim[reg_index] 
    else:
        raise NotImplementedError(
            &#34;Unknown special register: {}&#34;.format(reg_name)
        )
    return </code></pre>
</details>
</dd>
<dt id="simulator.subcore.Subcore.get_subcore_reg_addr"><code class="name flex">
<span>def <span class="ident">get_subcore_reg_addr</span></span>(<span>self, reg_prefix, reg_index, entry_id)</span>
</code></dt>
<dd>
<div class="desc"><p>This function calculates the absolute addrss of a register in the
register file of subcore. It also returns the size of registers with
the same name across threads in the whole warp.
</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>reg_prefix</code></strong></dt>
<dd>the prefix of register name </dd>
<dt><strong><code>reg_index</code></strong></dt>
<dd>the index of the register </dd>
<dt><strong><code>entry_id</code></strong></dt>
<dd>the warp ID of this register </dd>
</dl>
<h2 id="returns">Returns</h2>
<p>(reg_addr, reg_size): the stating address of this register in the
register file and the size of the whole register</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_subcore_reg_addr(self, reg_prefix, reg_index, entry_id):
    &#34;&#34;&#34;This function calculates the absolute addrss of a register in the 
    register file of subcore. It also returns the size of registers with 
    the same name across threads in the whole warp.  
    
    Args:
        reg_prefix: the prefix of register name 
        reg_index: the index of the register 
        entry_id: the warp ID of this register 

    Returns:
        (reg_addr, reg_size): the stating address of this register in the 
            register file and the size of the whole register 
    &#34;&#34;&#34;
    reg_base_addr = self.warp_info_table\
        .entry[entry_id].subcore_reg_base_addr 
    prefix_reg_base_addr = (
        reg_base_addr 
        + self.warp_info_table.entry[entry_id].prog_reg_offset[reg_prefix]
    )
    reg_size = self.warp_info_table\
        .entry[entry_id].prog_reg_size[reg_prefix]
    reg_addr = prefix_reg_base_addr + reg_index * reg_size

    self.log.debug(
        &#34;{loc} Entry {entry_id} {reg_prefix}{reg_index} &#34; 
        &#34;starting from {reg_addr} with size {reg_size}&#34;.format(
            loc=self._loc_str, entry_id=entry_id, 
            reg_prefix=reg_prefix, reg_index=reg_index,
            reg_addr=reg_addr, reg_size=reg_size 
        )
    )
    return (reg_addr, reg_size)</code></pre>
</details>
</dd>
<dt id="simulator.subcore.Subcore.reset_status"><code class="name flex">
<span>def <span class="ident">reset_status</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Reset hardware status of subcores.This function is usually used
to reset subcore status between different calls of executing thread
blocks.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def reset_status(self):
    &#34;&#34;&#34;Reset hardware status of subcores.This function is usually used 
    to reset subcore status between different calls of executing thread 
    blocks. 
    &#34;&#34;&#34;
    self.num_active_warps = 0
    self.reg_base_ptr = 0

    # Reset the tables in the subcore  
    self.warp_info_table.reset()
    self.warp_pipeline_table.reset() 
    self.stack_table.reset() 
    self.dep_table.reset()
    self.reg_track_table.reset()

    return </code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="simulator" href="index.html">simulator</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="simulator.subcore.Subcore" href="#simulator.subcore.Subcore">Subcore</a></code></h4>
<ul class="">
<li><code><a title="simulator.subcore.Subcore.check_reg_usage" href="#simulator.subcore.Subcore.check_reg_usage">check_reg_usage</a></code></li>
<li><code><a title="simulator.subcore.Subcore.check_warp_usage" href="#simulator.subcore.Subcore.check_warp_usage">check_warp_usage</a></code></li>
<li><code><a title="simulator.subcore.Subcore.get_param_value" href="#simulator.subcore.Subcore.get_param_value">get_param_value</a></code></li>
<li><code><a title="simulator.subcore.Subcore.get_special_reg_value" href="#simulator.subcore.Subcore.get_special_reg_value">get_special_reg_value</a></code></li>
<li><code><a title="simulator.subcore.Subcore.get_subcore_reg_addr" href="#simulator.subcore.Subcore.get_subcore_reg_addr">get_subcore_reg_addr</a></code></li>
<li><code><a title="simulator.subcore.Subcore.reset_status" href="#simulator.subcore.Subcore.reset_status">reset_status</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.8.3</a>.</p>
</footer>
</body>
</html>